gam_mod <- gam(cbind(n_positive, n_neg) ~ cv_predictions +
s(X, Y),
data = train_data,
family="binomial")
pred_data$cv_predictions <- pred_data$fitted_predictions
exceedance_probs <- exceedance_prob(gam_mod, pred_data, 200, 0.1)
plot(exceedance_probs, old_prediction$exceedance_probability)
sum(old_prediction$exceedance_probability >0.8 )
sum(old_prediction$exceedance_probability >=0.8 & exceedance_probs>=0.8)
sum(old_prediction$exceedance_probability >=0.8 )
54/113
plot(mod_data$n_positive/mod_data$n_trials, predict(gam_mod, mod_data, type="response"))
abline(0,1)
gam_mod <- gam(cbind(n_positive, n_neg) ~ cv_predictions +
s(X, Y, bs="gp"),
data = train_data,
family="binomial")
plot(mod_data$n_positive/mod_data$n_trials, predict(gam_mod, mod_data, type="response"))
gam_mod <- gam(cbind(n_positive, n_neg) ~ s(cv_predictions) +
s(X, Y, bs="gp"),
data = train_data,
family="binomial")
plot(mod_data$n_positive/mod_data$n_trials, predict(gam_mod, mod_data, type="response"))
plot(gam_mod)
gam_mod <- gam(cbind(n_positive, n_neg) ~ cv_predictions +
s(X, Y, bs="gp"),
data = train_data,
family="binomial")
AIC(gam_mod)
gam_mod <- gam(cbind(n_positive, n_neg) ~ s(cv_predictions) +
s(X, Y, bs="gp"),
data = train_data,
family="binomial")
AIC(gam_mod)
library(oro.nifti)
# Plot results
col_pal <- colorNumeric(tim.colors(), c(0,1))
leaflet() %>% addTiles() %>% addCircleMarkers(data = mod_data_sf,
col = col_pal(mod_data_sf$n_positive / mod_data_sf$n_trials))
mod_data_sf$n_positive / mod_data_sf$n_trials
mod_data$n_trials
mod_data$n_positive
leaflet() %>% addTiles() %>% addCircleMarkers(data = mod_data_sf,
col = col_pal(mod_data$n_positive / mod_data$n_trials))
leaflet() %>% addTiles() %>% addCircleMarkers(data = mod_data_sf,
col = col_pal(mod_data$n_positive / mod_data$n_trials),
radius=2)
mod_data$n_positive / mod_data$n_trials
leaflet() %>% addTiles() %>% addCircleMarkers(lng = train_data$X,
lat = train_data$Y,
col = col_pal(train_data$n_positive / train_data$n_trials),
radius=2)
leaflet() %>% addTiles() %>% addCircleMarkers(lng = train_data$X,
lat = train_data$Y,
col = col_pal(train_data$n_positive / train_data$n_trials),
radius=2, group = "training") %>%
addCircleMarkers(lng = pred_data$X,
lat = pred_data$Y,
col = col_pal(exceedance_probs),
radius=2, group = "prediction") %>%
addLayersControl(overlayGroups = c("training", "prediction"))
lf_data$region_definition$id
head(lf_data$region_definition$id)
head(lf_data$region_definition$id, 20)
head(old_prediction$ID, 20)
head(lf_data$region_definition)
# Save new predictions
old_prediction$exceedance_probability <- exceedance_probs
save(old_prediction, "/Users/sturrockh/Documents/Work/MEI/DiSARM/NTDs/LF/Samoa/2019_FIELD_LOCATIONS_with_predictions_7_23.CSV",
row.names=FALSE)
save(old_prediction, "/Users/sturrockh/Documents/Work/MEI/DiSARM/NTDs/LF/Samoa/2019_FIELD_LOCATIONS_with_predictions_7_23.CSV",
row.names=NULL)
save(old_prediction, file="/Users/sturrockh/Documents/Work/MEI/DiSARM/NTDs/LF/Samoa/2019_FIELD_LOCATIONS_with_predictions_7_23.CSV",
row.names=FALSE)
write.csv(old_prediction, file="/Users/sturrockh/Documents/Work/MEI/DiSARM/NTDs/LF/Samoa/2019_FIELD_LOCATIONS_with_predictions_7_23.CSV",
row.names=FALSE)
head(exceedance_probs)
head(exceedance_probs, 20)
response_content
response_content$result$importance
as.data.frame(response_content$result$importance)
matrix(response_content$result$importance, ncol=4)
summary(gam_mod)
pred_data$fitted_predictions
gam_mod_no_space <- gam(cbind(n_positive, n_neg) ~ s(cv_predictions),
data = train_data,
family="binomial")
AIC(gam_mod_no_space)
AIC(gam_mod)
substr("https", 1,2)
getwd()
setwd("~/Documents/Work/MEI/DiSARM/GitRepos/fn-ppmify/fn-ppmify")
library(jsonlite)
suppressPackageStartupMessages(library(geojsonio))
preprocess_params = dget('function/preprocess_params.R')
retrieve_remote_files = dget('function/retrieve_remote_files.R')
run_function = dget('function/function.R')
source("function/helpers.R")
run_function = dget('function/function.R')
# reads STDIN as JSON, return error if any problems
#params = fromJSON(readLines(file("stdin")))
params = fromJSON(readLines("test_req.json"))
# checks for existence of required parameters, return error if any problems
# checks types/structure of all parameters, return error if any problems
# as required, replace any external URLs with data
preprocess_params(params)
# if any parameters refer to remote files, try to download and
# replace parameter with local/temp file reference, return error if any problems
retrieve_remote_files(params)
params$points
as.json(params$points)
st_read(as.json(params$points))
tt<-st_read(as.json(params$points))
tt
library(jsonlite)
suppressPackageStartupMessages(library(geojsonio))
preprocess_params = dget('function/preprocess_params.R')
retrieve_remote_files = dget('function/retrieve_remote_files.R')
run_function = dget('function/function.R')
# reads STDIN as JSON, return error if any problems
#params = fromJSON(readLines(file("stdin")))
params = fromJSON(readLines("test_req.json"))
# checks for existence of required parameters, return error if any problems
# checks types/structure of all parameters, return error if any problems
# as required, replace any external URLs with data
preprocess_params(params)
# if any parameters refer to remote files, try to download and
# replace parameter with local/temp file reference, return error if any problems
retrieve_remote_files(params)
rm(list=ls())
library(jsonlite)
suppressPackageStartupMessages(library(geojsonio))
preprocess_params = dget('function/preprocess_params.R')
retrieve_remote_files = dget('function/retrieve_remote_files.R')
run_function = dget('function/function.R')
params = fromJSON(readLines("test_req.json"))
# checks for existence of required parameters, return error if any problems
# checks types/structure of all parameters, return error if any problems
# as required, replace any external URLs with data
preprocess_params(params)
# if any parameters refer to remote files, try to download and
# replace parameter with local/temp file reference, return error if any problems
retrieve_remote_files(params)
params$points
library(jsonlite)
suppressPackageStartupMessages(library(geojsonio))
preprocess_params = dget('function/preprocess_params.R')
retrieve_remote_files = dget('function/retrieve_remote_files.R')
run_function = dget('function/function.R')
main = function () {
params = fromJSON(readLines("test_req.json"))
# checks for existence of required parameters, return error if any problems
# checks types/structure of all parameters, return error if any problems
# as required, replace any external URLs with data
preprocess_params(params)
# if any parameters refer to remote files, try to download and
# replace parameter with local/temp file reference, return error if any problems
retrieve_remote_files(params)
substr(params$points, 1, 4)=="http"
substr(params$points, 1, 4)
substr(params$points, 1, 4)=="http"
params$points
if(substr(params$points, 1, 4)=="http"){
params$points <- st_read(params$points)
}else{
params$points <- st_read(as.json(params$points))
}
params$points
library(jsonlite)
suppressPackageStartupMessages(library(geojsonio))
preprocess_params = dget('function/preprocess_params.R')
retrieve_remote_files = dget('function/retrieve_remote_files.R')
run_function = dget('function/function.R')
params = fromJSON(readLines("test_req.json"))
# checks for existence of required parameters, return error if any problems
# checks types/structure of all parameters, return error if any problems
# as required, replace any external URLs with data
preprocess_params(params)
# if any parameters refer to remote files, try to download and
# replace parameter with local/temp file reference, return error if any problems
retrieve_remote_files(params)
params$points
params$offset
library(jsonlite)
suppressPackageStartupMessages(library(geojsonio))
preprocess_params = dget('function/preprocess_params.R')
retrieve_remote_files = dget('function/retrieve_remote_files.R')
run_function = dget('function/function.R')
params = fromJSON(readLines("test_req.json"))
# checks for existence of required parameters, return error if any problems
# checks types/structure of all parameters, return error if any problems
# as required, replace any external URLs with data
preprocess_params(params)
# if any parameters refer to remote files, try to download and
# replace parameter with local/temp file reference, return error if any problems
retrieve_remote_files(params)
params$offset
library(jsonlite)
suppressPackageStartupMessages(library(geojsonio))
preprocess_params = dget('function/preprocess_params.R')
retrieve_remote_files = dget('function/retrieve_remote_files.R')
run_function = dget('function/function.R')
params = fromJSON(readLines("test_req.json"))
# checks for existence of required parameters, return error if any problems
# checks types/structure of all parameters, return error if any problems
# as required, replace any external URLs with data
preprocess_params(params)
# if any parameters refer to remote files, try to download and
# replace parameter with local/temp file reference, return error if any problems
params <- retrieve_remote_files(params)
params$points
points <- params$points
offset_raster <- params$offset
reference_raster <- offset_raster # TODO - allow this to be controlled as parameter in function when offset not provided using boundary and resolution
points_coords <- st_coordinates(points)
# Make ppmify object
ppmx <- ppmify::ppmify(points_coords,
area = offset_raster,
#covariates = offset_raster,
density = params$density, #TODO change to be automatic
method = "grid")
# Aggregate points in space/time (i.e. aggregate points in same pixel)
ppm_cases_points_counts <- aggregate_points_space_time(points, ppmx, 3)
offset_raster
source('~/Documents/Work/MEI/DiSARM/GitRepos/fn-ppmify/fn-ppmify/function/helpers.R')
# Aggregate points in space/time (i.e. aggregate points in same pixel)
ppm_cases_points_counts <- aggregate_points_space_time(points, ppmx, 3, reference_raster)
head(ppm_cases_points_counts)
# Make these population extractions the weights
ppm_cases_points_counts$weights <- raster::extract(offset_raster,
cbind(ppm_cases_points_counts$x, ppm_cases_points_counts$y))
head(ppm_cases_points_counts)
if(!is.null(params$offset)){
ppm_int_points_period <- get_int_points_offset_weights(ppmx, offset_raster, params$num_periods)
}
library(velox)
source('~/Documents/Work/MEI/DiSARM/GitRepos/fn-ppmify/fn-ppmify/function/helpers.R')
if(!is.null(params$offset)){
ppm_int_points_period <- get_int_points_offset_weights(ppmx, offset_raster, params$num_periods)
}
# add model month column for integration points (already generated as 'month')
ppm_df <- rbind(ppm_cases_points_counts, ppm_int_points_period)
# add column of 1's to cells with cases and 0's to cells without
# this will act as your outcome in the poisson model
ppm_df$outcome <- ifelse(ppm_df$points > 0, 1, 0)
# change any 0's in the points column to 1
# this will act as regression weights in the poisson model
ppm_df$regression_weights <- ppm_df$points
ppm_df$regression_weights[ppm_df$regression_weights == 0] <- 1
# divide the offset by the number of cases in each cell
ppm_df$weights <- ppm_df$weights/ppm_df$regression_weights
head(ppm_df)
dim(ppm_df)
sum(ppm_df$outcome)
sum(ppm_df$weights)
sum(ppm_df$weights)/3
table(ppm_df$period)
# Generate some points
swz_elev <- getData("alt", country="elev")
# Generate some points
swz_elev <- getData("alt", country="SWZ")
swz_elev <- swz_elev / sum(swz_elev[])
plot(swz_elev)
cellStats(swz_elev, sum)
# Generate some points
swz_elev <- getData("alt", country="SWZ")
plot(swz_elev)
swz_elev <- swz_elev / cellStats(swz_elev, sum)
plot(swz_elev)
?sample
points <- sample(1:length(swz_elev[]), 1000, prob=swz_elev[])
swz_elev[is.na(swz_elev[])] <- 0
points <- sample(1:length(swz_elev[]), 1000, prob=swz_elev[])
plot(swz_elev)
points(points)
points_index <- sample(1:length(swz_elev[]), 1000, prob=swz_elev[])
points <- coordinates(swz_elev)[points_index,]
points(points)
swz_elev <- 1/swz_elev
# Generate some points
swz_elev <- getData("alt", country="SWZ")
swz_elev <- 1/swz_elev
swz_elev <- swz_elev / cellStats(swz_elev, sum)
swz_elev[is.na(swz_elev[])] <- 0
points_index <- sample(1:length(swz_elev[]), 1000, prob=swz_elev[])
points <- coordinates(swz_elev)[points_index,]
plot(swz_elev); points(points)
st_write(st_as_sf(SpatialPoints(points)), "~/Dropbox/Random/test_points_swz.geojson")
rm(list=ls())
library(jsonlite)
suppressPackageStartupMessages(library(geojsonio))
preprocess_params = dget('function/preprocess_params.R')
retrieve_remote_files = dget('function/retrieve_remote_files.R')
run_function = dget('function/function.R')
# reads STDIN as JSON, return error if any problems
#params = fromJSON(readLines(file("stdin")))
params = fromJSON(readLines("test_req.json"))
# checks for existence of required parameters, return error if any problems
# checks types/structure of all parameters, return error if any problems
# as required, replace any external URLs with data
preprocess_params(params)
# if any parameters refer to remote files, try to download and
# replace parameter with local/temp file reference, return error if any problems
params <- retrieve_remote_files(params)
params$points
# run the function with parameters,
# return error if any problems, return success if succeeds
function_response = run_function(params)
points <- params$points
offset_raster <- params$offset
reference_raster <- offset_raster # TODO - allow this to be controlled as parameter in function when offset not provided using boundary and resolution
points_coords <- st_coordinates(points)
# Make ppmify object
ppmx <- ppmify::ppmify(points_coords,
area = offset_raster,
#covariates = offset_raster,
density = params$density, #TODO change to be automatic
method = "grid")
# Aggregate points in space/time (i.e. aggregate points in same pixel)
ppm_cases_points_counts <- aggregate_points_space_time(points, ppmx, 3, reference_raster)
source('~/Documents/Work/MEI/DiSARM/GitRepos/fn-ppmify/fn-ppmify/function/helpers.R')
# Aggregate points in space/time (i.e. aggregate points in same pixel)
ppm_cases_points_counts <- aggregate_points_space_time(points, ppmx, 3, reference_raster)
ppm_cases_points <- ppmx[ppmx$points==1,]
ppm_cases_points_counts <- ppm_cases_points[FALSE,]
num_periods
i<-1
cases_model_period <- as.numeric(cut.Date(ymd(points$date), num_periods))
swz_elev <- getData("alt", country="SWZ")
swz_elev <- 1/swz_elev
swz_elev <- swz_elev / cellStats(swz_elev, sum)
swz_elev[is.na(swz_elev[])] <- 0
points_index <- sample(1:length(swz_elev[]), 1000, prob=swz_elev[])
points <- coordinates(swz_elev)[points_index,]
plot(swz_elev); points(points)
?as.Date()
seq(from = ymd("2018-01-01"), to = ymd("2018-12-31"), by = )
seq(from = ymd("2018-01-01"), to = ymd("2018-12-31"), by = 1)
dates  <- seq(from = ymd("2018-01-01"), to = ymd("2018-12-31"), by = 1)
points$date <- dates[sample(1:1000, 1000, replace = TRUE)]
sample(1:1000, 1000, replace = TRUE)
dates[sample(1:1000, 1000, replace = TRUE)]
dates[sample(1:365, 1000, replace = TRUE)]
points <- coordinates(swz_elev)[points_index,]
points$date <- dates[sample(1:365, 1000, replace = TRUE)]
points
dates[sample(1:365, 1000, replace = TRUE)]
points <- coordinates(swz_elev)[points_index,]
points <- as.data.frame(coordinates(swz_elev)[points_index,])
points$date <- dates[sample(1:365, 1000, replace = TRUE)]
head(points)
st_write(st_as_sf(SpatialPoints(points)), "~/Dropbox/Random/test_points_swz.geojson")
data = data.frame(date = points$date)), "~/Dropbox/Random/test_points_swz.geojson")
st_write(st_as_sf(SpatialPointsDataFrame(SpatialPoints(points),
data = data.frame(date = points$date))), "~/Dropbox/Random/test_points_swz.geojson")
data.frame(date = points$date)
st_write(st_as_sf(SpatialPointsDataFrame(SpatialPoints(points),
data.frame(date = points$date))), "~/Dropbox/Random/test_points_swz.geojson")
SpatialPoints(points)
st_write(st_as_sf(SpatialPointsDataFrame(SpatialPoints(points[,c("x", "y")]),
data.frame(date = points$date))), "~/Dropbox/Random/test_points_swz.geojson")
st_write(st_as_sf(SpatialPointsDataFrame(SpatialPoints(points[,c("x", "y")]),
data.frame(date = points$date))), "~/Dropbox/Random/test_points_swz.geojson")
library(jsonlite)
suppressPackageStartupMessages(library(geojsonio))
preprocess_params = dget('function/preprocess_params.R')
retrieve_remote_files = dget('function/retrieve_remote_files.R')
run_function = dget('function/function.R')
params = fromJSON(readLines("test_req.json"))
# checks for existence of required parameters, return error if any problems
# checks types/structure of all parameters, return error if any problems
# as required, replace any external URLs with data
preprocess_params(params)
# if any parameters refer to remote files, try to download and
# replace parameter with local/temp file reference, return error if any problems
params <- retrieve_remote_files(params)
source('~/Documents/Work/MEI/DiSARM/GitRepos/fn-ppmify/fn-ppmify/function/helpers.R')
# run the function with parameters,
# return error if any problems, return success if succeeds
function_response = run_function(params)
dim(function_response)
head(function_response)
sum(function_response$outcome)
sum(function_response$weights)
ppm_df<- function_response
test_gam <- gam(outcome ~ s(x, y),
offset = log(ppm_df$weights),
weights = ppm_df$regression_weights,
data =ppm_df,
family="poisson")
sum(is.na(ppm_df$regression_weights))
ppm_df$regression_weights
sum(ppm_df$regression_weights)
lenght(ppm_df$regression_weights)
length(ppm_df$regression_weights)
head(log(ppm_df$weights))
sum(log(ppm_df$weights)=="-Inf")
sum(is.na(log(ppm_df$weights)))
log(0)
ppm_df <- ppm_df[-which(ppm_df$weights==0),]
test_gam <- gam(outcome ~ s(x, y),
offset = log(ppm_df$weights),
weights = ppm_df$regression_weights,
data =ppm_df,
family="poisson")
offset_raster_coords <- data.frame(coordinates(offset_raster)[!is.na(offset_raster[]),])
prediction <- exp(predict(test_gam, newdata=offset_raster_coords) + log(offset_raster[!is.na(offset_raster[])]))
pred_raster <- offset_raster
pred_raster[!is.na(offset_raster[])] <- prediction / offset_raster[!is.na(offset_raster[])]
plot(pred_raster)
cellStats(prediction, sum)
prediction
sum(prediction)
source('~/Documents/Work/MEI/DiSARM/GitRepos/fn-ppmify/fn-ppmify/function/helpers.R')
ppm_int_points_period <- get_int_points_offset_weights(ppmx, offset_raster, params$num_periods)
# First identify which are the local_cases and integration rows
# in the ppm object
ppm_int_points <- ppmx[ppmx$points==0,]
# extract population within each voronoi polygon around each integration point
# First remove any pixels with cases as you need to estimate population in pixels without cases
dd <- deldir::deldir(ppm_int_points$x, ppm_int_points$y)
tiles <- deldir::tile.list(dd)
offset_raster_non_case_pixels <- offset_raster
raster::cellFromXY(offset_raster_non_case_pixels,
points_coords)
points_coords
offset_raster_non_case_pixels[raster::cellFromXY(offset_raster_non_case_pixels,
points_coords)] <- NA
polys <- vector(mode = "list", length = length(tiles))
for (i in seq(along = polys)) {
pcrds <- cbind(tiles[[i]]$x, tiles[[i]]$y)
pcrds <- rbind(pcrds, pcrds[1,])
polys[[i]] <- sp::Polygons(list(sp::Polygon(pcrds)), ID = as.character(i))
}
spoly <- sp::SpatialPolygons(polys)
polys
tiles
source('~/Documents/Work/MEI/DiSARM/GitRepos/fn-ppmify/fn-ppmify/function/helpers.R')
ppm_int_points_period <- get_int_points_offset_weights(ppmx, offset_raster, params$num_periods)
# Extract from offset raster
offset_raster_velox <- velox(offset_raster_non_case_pixels)
ppm_int_points$weights <- offset_raster_velox$extract(spoly, fun = function(x){sum(x, na.rm = TRUE)})
sum(ppm_int_points$weights)
source('~/Documents/Work/MEI/DiSARM/GitRepos/fn-ppmify/fn-ppmify/function/helpers.R')
run_function = dget('function/function.R')
# run the function with parameters,
# return error if any problems, return success if succeeds
function_response = run_function(params)
ppm_df<-function_response
sum(ppm_df$weights)
ppm_df <- ppm_df[-which(ppm_df$weights==0),]
test_gam <- gam(outcome ~ s(x, y),
offset = log(ppm_df$weights),
weights = ppm_df$regression_weights,
data =ppm_df,
family="poisson")
offset_raster_coords <- data.frame(coordinates(offset_raster)[!is.na(offset_raster[]),])
prediction <- exp(predict(test_gam, newdata=offset_raster_coords) + log(offset_raster[!is.na(offset_raster[])]))
pred_raster <- offset_raster
pred_raster[!is.na(offset_raster[])] <- prediction / offset_raster[!is.na(offset_raster[])]
plot(pred_raster)
sum(prediction)
?ppmify
head(ppm_df)
library(mgcv)
?bam.update()
offset_raster
0.008333*111
# Get covariate values at data and prediction points
ppm_df_sf <- st_as_sf(SpatialPointsDataFrame(SpatialPoints(ppm_df[,c("x", "y")]),
ppm_df))
ppm_df_sf
?sfc
pt1 = st_point(c(0,1))
pt2 = st_point(c(1,1))
(sfc = st_sfc(pt1, pt2))
d = st_sf(data.frame(a=1:2, geom=sfc))
d
st_point(ppm_df[,c("x", "y")])
ppm_df[,c("x", "y")]
st_multipoint(ppm_df[,c("x", "y")])
st_point(as.matrix(ppm_df[,c("x", "y")]))
st_multipoint(as.matrix(ppm_df[,c("x", "y")]))
tt<-st_multipoint(as.matrix(ppm_df[,c("x", "y")]))
st_sfc(tt)
c("elev_m", "dist_to_water_m", paste0("bioclim", c(1, 4, 12, 15))
)
input_data_list <- list(
points = geojson_list(ppm_df_sf),
layer_names = c("elev_m", "dist_to_water_m", paste0("bioclim", c(1, 4, 12, 15)))
)
response <-
httr::POST(
url = "https://faas.srv.disarm.io/function/fn-covariate-extractor",
body = as.json(input_data_list),
content_type_json(),
timeout(90)
)
response <-
httr::POST(
url = "https://faas.srv.disarm.io/function/fn-covariate-extractor",
body = as.json(input_data_list),
content_type_json(),
timeout(300)
)
response$status_code
response_content <- content(response)
ppm_df_sf <- st_read(as.json(response_content$result))
head(ppm_df_sf)
# Get covariate values at data and prediction points
# AT data points
ppm_df_sf <- st_as_sf(SpatialPoints(ppm_df[,c("x", "y")]))
